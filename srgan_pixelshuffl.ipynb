{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"srgan_pixelshuffl.ipynb","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"7kB4H98sbNgq","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"LvH88TmZbWRd","colab_type":"code","colab":{}},"source":["%tensorflow_version 1.x\n","import scipy\n","import glob\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import random\n","import cv2\n","from PIL import Image\n","import math\n","\n","class DataLoader():\n","    def __init__(self, dataset_name, img_res=(480, 480)):\n","        self.dataset_name = dataset_name\n","        self.img_res = img_res\n","\n","    def load_data(self, batch_size=1, is_testing=False):\n","        # random.seed(0)\n","        # np.random.seed(0)\n","        data_type = \"train\" if not is_testing else \"test\"\n","\n","        files = glob.glob(\"drive/My Drive/tana_data3/*\", recursive=True)\n","        batch_images = random.sample(files, batch_size)\n","\n","        imgs_hr = []\n","        imgs_lr = []\n","        for img_path in batch_images:\n","            img = Image.open(img_path)\n","\n","            h, w = self.img_res\n","\n","            moz_h, moz_w = int(h / 10), int(w / 10)\n","            img_m=img.resize((moz_h, moz_w))\n","\n","            low_h, low_w = int(h / 4), int(w / 4)\n","\n","            img_hr = img.resize((h, w)) \n","            img_lr = img_m.resize((low_h, low_w))\n","            img_hr = np.array(img_hr)\n","            #img_hr = (img_hr - 127.5) / 127.5\n","            img_lr = np.array(img_lr)\n","            #img_lr = (img_lr - 127.5) / 127.5\n","\n","            if not is_testing and np.random.random() < 0.5:\n","                img_hr = np.fliplr(img_hr)\n","                img_lr = np.fliplr(img_lr)\n","\n","            imgs_hr.append(img_hr)\n","            imgs_lr.append(img_lr)\n","\n","        imgs_hr = np.array(imgs_hr) / 127.5 - 1.\n","        imgs_lr = np.array(imgs_lr) / 127.5 - 1.\n","\n","        return imgs_hr, imgs_lr"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"YOsaSeg8bulR","colab_type":"code","colab":{}},"source":["class predDataLoader():          \n","    def load_data(self, batch_size,cnt):\n","        random.seed(cnt)\n","        np.random.seed(cnt)\n","\n","        files = glob.glob(\"drive/My Drive/tana_data_test2/*\", recursive=True)\n","        batch_images = random.sample(files, batch_size)\n","\n","        imgs_or = []\n","        for img_path in batch_images:\n","            img = Image.open(img_path)\n","\n","            img_or = np.array(img)\n","            imgs_or.append(img_or)\n","\n","        imgs_or = np.array(imgs_or) / 127.5 - 1.\n","\n","        return imgs_or"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hIblmGtQbZ2n","colab_type":"code","colab":{}},"source":["\n","\n","from __future__ import print_function, division\n","import scipy\n","\n","from keras.datasets import mnist\n","# from keras_contrib.layers.normalization.instancenormalization import InstanceNormalization\n","from keras.layers import Input, Dense, Reshape, Flatten, Dropout, Concatenate\n","from keras.layers import BatchNormalization, Activation, ZeroPadding2D, Add\n","from keras.layers.advanced_activations import PReLU, LeakyReLU\n","from keras.layers import Lambda\n","from keras.layers.convolutional import UpSampling2D, Conv2D\n","from keras.applications import VGG19\n","from keras.models import Sequential, Model\n","from keras.optimizers import Adam\n","import datetime\n","import matplotlib.pyplot as plt\n","import sys\n","# from data_loader import DataLoader\n","import numpy as np\n","import os\n","import csv\n","import keras.backend as K\n","\n","class SRGAN():\n","    def __init__(self):\n","        # Input shape\n","        self.channels = 3\n","        self.lr_height = 120                 # Low resolution height\n","        self.lr_width = 120                  # Low resolution width\n","        self.lr_shape = (self.lr_height, self.lr_width, self.channels)\n","        self.hr_height = self.lr_height*4   # High resolution height\n","        self.hr_width = self.lr_width*4     # High resolution width\n","        self.hr_shape = (self.hr_height, self.hr_width, self.channels)\n","\n","        # Number of residual blocks in the generator\n","        self.n_residual_blocks = 16\n","\n","        optimizer = Adam(0.0002, 0.5)\n","\n","        # We use a pre-trained VGG19 model to extract image features from the high resolution\n","        # and the generated high resolution images and minimize the mse between them\n","        self.vgg = self.build_vgg()\n","        self.vgg.trainable = False\n","        self.vgg.compile(loss='mse',\n","            optimizer=optimizer,\n","            metrics=['accuracy'])\n","\n","        # Configure data loader\n","        self.dataset_name = 'img_align_celeba'\n","        self.data_loader = DataLoader(dataset_name=self.dataset_name,\n","                                      img_res=(self.hr_height, self.hr_width))\n","\n","        # Calculate output shape of D (PatchGAN)\n","        patch = int(self.hr_height / 2**4)\n","        self.disc_patch = (patch, patch, 1)\n","\n","        # Number of filters in the first layer of G and D\n","        self.gf = 120\n","        self.df = 120\n","\n","        # Build and compile the discriminator\n","        self.discriminator = self.build_discriminator()\n","        self.discriminator.compile(loss='mse',\n","            optimizer=optimizer,\n","            metrics=['accuracy'])\n","\n","        # Build the generator\n","        self.generator = self.build_generator()\n","\n","        # High res. and low res. images\n","        img_hr = Input(shape=self.hr_shape)\n","        img_lr = Input(shape=self.lr_shape)\n","\n","        # Generate high res. version from low res.\n","        fake_hr = self.generator(img_lr)\n","\n","        # Extract image features of the generated img\n","        fake_features = self.vgg(fake_hr)\n","\n","        # For the combined model we will only train the generator\n","        self.discriminator.trainable = False\n","\n","        # Discriminator determines validity of generated high res. images\n","        validity = self.discriminator(fake_hr)\n","\n","        self.combined = Model([img_lr, img_hr], [validity, fake_features])\n","        self.combined.compile(loss=['binary_crossentropy', 'mse'],\n","                              loss_weights=[1e-3, 1],\n","                              optimizer=optimizer)\n","\n","\n","    def build_vgg(self):\n","        \"\"\"\n","        Builds a pre-trained VGG19 model that outputs image features extracted at the\n","        third block of the model\n","        \"\"\"\n","        vgg = VGG19(weights=\"imagenet\")\n","        # Set outputs to outputs of last conv. layer in block 3\n","        # See architecture at: https://github.com/keras-team/keras/blob/master/keras/applications/vgg19.py\n","        vgg.outputs = [vgg.layers[9].output]\n","\n","        img = Input(shape=self.hr_shape)\n","\n","        # Extract image features\n","        img_features = vgg(img)\n","\n","        return Model(img, img_features)\n","\n","    def build_generator(self):\n","\n","        def residual_block(layer_input, filters):\n","            \"\"\"Residual block described in paper\"\"\"\n","            d = Conv2D(filters, kernel_size=3, strides=1, padding='same')(layer_input)\n","            d = Activation('relu')(d)\n","            d = BatchNormalization(momentum=0.8)(d)\n","            d = Conv2D(filters, kernel_size=3, strides=1, padding='same')(d)\n","            d = BatchNormalization(momentum=0.8)(d)\n","            d = Add()([d, layer_input])\n","            return d\n","\n","        def deconv2d(layer_input):\n","            \"\"\"Layers used during upsampling\"\"\"\n","            def pixelshuffler(inputs):\n","              # print(input_shape.shape)\n","              input_shape = K.int_shape(inputs)\n","              # inputs=input_shape.shape\n","\n","              batch_size, h, w, c = input_shape\n","              if batch_size is None:\n","                batch_size = -1\n","              batch_size = -1\n","              rh, rw = (2, 2)\n","              oh, ow = h * rh, w * rw\n","              oc = c // (rh * rw)\n","\n","              out = K.reshape(inputs, (batch_size, h, w, rh, rw, oc))\n","              out = K.permute_dimensions(out, (0, 1, 3, 2, 4, 5))\n","              out = K.reshape(out, (batch_size, oh, ow, oc))\n","              return out\n","\n","            # u = UpSampling2D(size=2)(layer_input)\n","            # u = Conv2D(480, kernel_size=3, strides=1, padding='same')(u)\n","            # u = Activation('relu')(u)\n","            u = Conv2D(480, kernel_size=3, strides=1,padding='same')(layer_input)\n","            u = Lambda(lambda u: pixelshuffler(u))(u)\n","            u = LeakyReLU(alpha=0.2)(u)\n","            return u\n","\n","        # Low resolution image input\n","        img_lr = Input(shape=self.lr_shape)\n","\n","        # Pre-residual block\n","        c1 = Conv2D(120, kernel_size=9, strides=1, padding='same')(img_lr)\n","        c1 = Activation('relu')(c1)\n","\n","        # Propogate through residual blocks\n","        r = residual_block(c1, self.gf)\n","        for _ in range(self.n_residual_blocks - 1):\n","            r = residual_block(r, self.gf)\n","\n","        # Post-residual block\n","        c2 = Conv2D(120, kernel_size=3, strides=1, padding='same')(r)\n","        c2 = BatchNormalization(momentum=0.8)(c2)\n","        c2 = Add()([c2, c1])\n","\n","        # Upsampling\n","        u1 = deconv2d(c2)\n","        u2 = deconv2d(u1)\n","\n","        # Generate high resolution output\n","        gen_hr = Conv2D(self.channels, kernel_size=9, strides=1, padding='same', activation='tanh')(u2)\n","\n","        return Model(img_lr, gen_hr)\n","\n","    def build_discriminator(self):\n","\n","        def d_block(layer_input, filters, strides=1, bn=True):\n","            \"\"\"Discriminator layer\"\"\"\n","            d = Conv2D(filters, kernel_size=3, strides=strides, padding='same')(layer_input)\n","            d = LeakyReLU(alpha=0.2)(d)\n","            if bn:\n","                d = BatchNormalization(momentum=0.8)(d)\n","            return d\n","\n","        # Input img\n","        d0 = Input(shape=self.hr_shape)\n","\n","        d1 = d_block(d0, self.df, bn=False)\n","        d2 = d_block(d1, self.df, strides=2)\n","        d3 = d_block(d2, self.df*2)\n","        d4 = d_block(d3, self.df*2, strides=2)\n","        d5 = d_block(d4, self.df*4)\n","        d6 = d_block(d5, self.df*4, strides=2)\n","        d7 = d_block(d6, self.df*8)\n","        d8 = d_block(d7, self.df*8, strides=2)\n","\n","        d9 = Dense(self.df*16)(d8)\n","        d10 = LeakyReLU(alpha=0.2)(d9)\n","        validity = Dense(1, activation='sigmoid')(d10)\n","\n","        return Model(d0, validity)\n","\n","    def train(self, epochs, batch_size, sample_interval=100):\n","\n","        start_time = datetime.datetime.now()\n","        psnr_file = open('psnr.csv' , 'w+')\n","        psnr_file.close()\n","\n","        for epoch in range(epochs):\n","\n","            # ----------------------\n","            #  Train Discriminator\n","            # ----------------------\n","\n","            # Sample images and their conditioning counterparts\n","            imgs_hr, imgs_lr = self.data_loader.load_data(batch_size)\n","\n","            # From low res. image generate high res. version\n","            fake_hr = self.generator.predict(imgs_lr)\n","\n","            valid = np.ones((batch_size,) + self.disc_patch)\n","            fake = np.zeros((batch_size,) + self.disc_patch)\n","\n","            # Train the discriminators (original images = real / generated = Fake)\n","            d_loss_real = self.discriminator.train_on_batch(imgs_hr, valid)\n","            d_loss_fake = self.discriminator.train_on_batch(fake_hr, fake)\n","            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n","\n","            # ------------------\n","            #  Train Generator\n","            # ------------------\n","\n","            # Sample images and their conditioning counterparts\n","            imgs_hr, imgs_lr = self.data_loader.load_data(batch_size)\n","\n","            # The generators want the discriminators to label the generated images as real\n","            valid = np.ones((batch_size,) + self.disc_patch)\n","\n","            # Extract ground truth image features using pre-trained VGG19 model\n","            image_features = self.vgg.predict(imgs_hr)\n","\n","            # Train the generators\n","            g_loss = self.combined.train_on_batch([imgs_lr, imgs_hr], [valid, image_features])\n","\n","            elapsed_time = datetime.datetime.now() - start_time\n","            # Plot the progress\n","            print (\"%d time: %s\" % (epoch, elapsed_time))\n","\n","            # If at save interval => save generated image samples\n","            if epoch % sample_interval == 0:\n","                self.sample_images(epoch)\n","                self.generator.save_weights('srg_waight_pix.h5')\n","\n","    def sample_images(self, epoch):\n","        def denormalize(input_data):\n","            input_data = (input_data + 1) * 127.5\n","            return input_data.astype(np.uint8)\n","        os.makedirs('images/%s' % self.dataset_name, exist_ok=True)\n","        r, c = 2, 2\n","\n","        imgs_hr, imgs_lr = self.data_loader.load_data(batch_size=2, is_testing=True)\n","        fake_hr = self.generator.predict(imgs_lr)\n","\n","        imgs_lr = denormalize(imgs_lr)\n","        fake_hr = denormalize(fake_hr)\n","        imgs_hr = denormalize(imgs_hr)\n","\n","        def psnr_calc(img1: np.ndarray, img2: np.ndarray, upscaling=4):\n","            def convert(img):\n","                return cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","            def extract_y(image: np.ndarray) -> np.ndarray:\n","                if image.ndim == 2:\n","                    return image\n","                image = image.astype(np.int32)\n","                return ((image[:, :, 2] * 65.481 / 255.\n","                          + image[:, :, 1] * 128.553 / 255.\n","                          + image[:, :, 0] * 24.966 / 255.) + 16).astype(np.int32)\n","\n","\n","            def psnr(img1, img2):\n","                mse = np.mean((img1 - img2) ** 2)\n","                if mse == 0:\n","                    return 100\n","                PIXEL_MAX = 255.0\n","                return 10 * math.log10(PIXEL_MAX * PIXEL_MAX / mse)\n","  \n","            img1_conv=convert(img1)\n","            img2_conv=convert(img2)\n","  \n","            # BGR -> YCrCb\n","            # 画像はcv2.imreadで読まれている前提 [0, 255]\n","            y1 = extract_y(img1_conv)\n","            y2 = extract_y(img2_conv)\n","            # 周囲のcropping\n","            # assert y1.shape == y2.shape\n","            h, w = y1.shape\n","            cr = upscaling\n","            cropped_y1 = y1[cr:h - cr, cr:w - cr].astype(np.float64)\n","            cropped_y2 = y2[cr:h - cr, cr:w - cr].astype(np.float64)\n","\n","            # psnr\n","            psnr_val = psnr(cropped_y1, cropped_y2)\n","            return psnr_val\n","\n","        # Save generated images and the high resolution originals\n","        # calcurate psnr\n","        titles = ['Generated', 'Original']\n","        cv2.imwrite(\"images/hreal_img_0.png\",imgs_hr[0])\n","        cv2.imwrite(\"images/hreal_img_1.png\",imgs_hr[1])\n","        cv2.imwrite(\"images/lreal_img_0.png\",imgs_lr[0])\n","        cv2.imwrite(\"images/lreal_img_1.png\",imgs_lr[1])\n","\n","        for i in range(r):\n","            psnr = psnr_calc(imgs_hr[i],fake_hr[i])\n","            print(psnr)\n","            data =[epoch,psnr]\n","            psnr_file = open('psnr.csv' , 'a')\n","            writer = csv.writer(psnr_file, lineterminator='\\n')  \n","            writer.writerow(data)\n","            psnr_file.close()\n","            cv2.imwrite(\"images/{}_{}img_pred.png\".format(epoch,i),fake_hr[i])\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"yE-FOrRacBEC","colab_type":"code","colab":{}},"source":["if __name__ == '__main__':\n","    gan = SRGAN()\n","    gan.train(epochs=1000, batch_size=1, sample_interval=50)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"P0KT0B-w1Bek","colab_type":"code","colab":{}},"source":["with open('psnr.csv') as f:\n","    reader = csv.reader(f)\n","    psnr_array1=[]\n","    psnr_array2=[]\n","    epoch_array1=[]\n","    epoch_array2=[]\n","    cnt=1\n","    for row in reader:\n","        if(cnt%2 is 1):\n","          psnr_array1.append(float(row[1]))\n","          epoch_array1.append(int(row[0]))\n","        else:\n","          psnr_array2.append(float(row[1]))\n","          epoch_array2.append(int(row[0]))\n","        cnt+=1"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xXEzVp3PaFD1","colab_type":"code","colab":{}},"source":["import matplotlib.pyplot as plt\n","plt.plot(epoch_array1, psnr_array1)\n","plt.plot(epoch_array2, psnr_array2,color='red')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"z9MGzkonaGve","colab_type":"code","colab":{}},"source":["class Generate(SRGAN):\n","    def generate(self, batch_size=1, sample_interval=50):\n","        BATCH_SIZE=1\n","        ite=10000\n","        def denormalize(input_data):\n","            input_data = (input_data + 1) * 127.5\n","            return input_data.astype(np.uint8)\n","            \n","        self.generator = self.build_generator()\n","        g = self.generator\n","        g.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.0002, beta_1=0.5))\n","        g.load_weights('drive/My Drive/srg_waight_pix.h5')\n","        for i in range(10):\n","            noise = np.random.uniform(size=[BATCH_SIZE, 120*120*3], low=-1.0, high=1.0) ##32*32\n","            imgs_or = self.pred_data_loader.load_data(batch_size=1,cnt=i)\n","            # imgs_hr, imgs_or = self.data_loader.load_data(batch_size=BATCH_SIZE,is_testing=True)\n","\n","            plt.imshow(denormalize(imgs_or[0]))\n","            plt.pause(1)\n","            noise=imgs_or.reshape(BATCH_SIZE,120,120,3)\n","            generated_images = g.predict(noise)\n","            plt.imshow(denormalize(generated_images[0]))\n","            plt.pause(1)\n","            p_im=Image.fromarray(denormalize(generated_images[0]))\n","            p_im.save('p_im_{}.jpg'.format(i))\n","            # plt.imshow(p_im.resize((120,120)), Image.LANCZOS)\n","\n","            print(i)\n","        # os.makedirs(os.path.join(\".\", \"images\"), exist_ok=True)\n","        # image.save(\"./images/%s%d.png\" % (ite,i))            \n","\n","    def combine_images(generated_images, cols=5, rows=5):\n","        shape = generated_images.shape\n","        h = shape[1]\n","        w = shape[2]\n","        image = np.zeros((rows * h,  cols * w, 3))\n","        for index, img in enumerate(generated_images):\n","            if index >= cols * rows:\n","                break\n","            i = index // cols\n","            j = index % cols\n","            image[i*h:(i+1)*h, j*w:(j+1)*w, :] = img[:, :, :]\n","        image = image * 127.5 + 127.5\n","        image = Image.fromarray(image.astype(np.uint8))\n","        return image"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"e4TZL58XaI-o","colab_type":"code","colab":{}},"source":["if __name__ == '__main__':\n","    gene = Generate()\n","    gene.generate(batch_size=1, sample_interval=1000)"],"execution_count":0,"outputs":[]}]}